#ifndef X25519_AVX2_SCALARMULT
#define X25519_AVX2_SCALARMULT

// Jasmin version of: https://github.com/armfazh/fld-ecc-vec/

#define EXPORT

#include "crypto_scalarmult/curve25519/avx2/x25519_mul.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_sqr.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_addsub.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_inter.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_compress.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_swap.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_ser.jazz"
#include "crypto_scalarmult/curve25519/avx2/x25519_ladder.jazz"
#include "crypto_scalarmult/curve25519/mulx/x25519_scalarmult2.jazz"

inline fn __decode_scalar_sm(reg u64 kp) -> stack u64[4]
{
  inline int i;
  reg u64[4] k;
  stack u64[4] ks;

  for i=0 to 4
  { k[i] = [kp + 8*i]; }
  k[3] <<= 1;
  k[0] &= 0xfffffffffffffff8;
  k[3] |= 0x8000000000000000;

  ks = k;

  return ks;
}

inline fn __decode_u_coordinate_rm(reg u64 up) -> reg u64[4]
{
  inline int i;
  reg u64[4] u;

  for i=0 to 4
  { u[i] = [up + 8*i]; }
  u[3] &= 0x7fffffffffffffff;

  return u;
}

inline fn __x25519_scalarmult_avx2(
  reg u64 rp,
  reg u64 kp,
  reg u64 up
)
{
  inline int i;
  reg u64[4] u X Z r;
  stack u64[4] k Xs;
  reg u256[3] X1;
  stack u256[3] XX ZZ;
  reg u256[5] QxPx QzPz;
  stack u64 rps;

  //ZEROUPPER;
  rps = rp;
  
  k  = __decode_scalar_sm(kp);
  u  = __decode_u_coordinate_rm(up);
  X1 = __rrx_unser_rr(u);

  /* start with (kP,0P) */
  QzPz[0] = g_3one;
  for i=1 to 5
  { QzPz[i] = #set0_256(); }
  QxPx = __rrx_inter1_rr(X1);

  QxPx,QzPz = __rrx_step_ladder(k,QxPx,QzPz);
 
  XX = __rrx_deinter1_sr(QxPx);
  ZZ = __rrx_deinter1_sr(QzPz);
  X  = __rrx_ser_rs(XX); Xs = X;
  Z  = __rrx_ser_rs(ZZ);

  //ZEROUPPER;
  r = __encode_point(Xs, Z);

  rp = rps;
  for i=0 to 4
  { [rp + 8*i] = r[i]; }
}

export fn curve25519_avx2(reg u64 out scalar point)
{
  __x25519_scalarmult_avx2(out, scalar, point);
}

#endif

