#include "x25519_add.jazz"
#include "x25519_sub.jazz"
#include "x25519_mul121666.jazz"
#include "x25519_mul.jazz"
#include "x25519_sqr.jazz"
#include "x25519_invert.jazz"
#include "x25519_invert_regs.jazz"
#include "x25519_tobytes.jazz"
#include "x25519_frombytes.jazz"
#include "x25519_cswap.jazz"

fn _fe64_0_1_x2() -> reg u64[4], stack u64[4], stack u64[4]
{
  inline int i;
  reg   u64[4] f1s;
  stack u64[4] f2s f3s;
  reg u64 z;

  z = #set0();

  f1s[0] = z;
  f2s[0] = 1;
  f3s[0] = 1;

  for i=1 to 4
  { f1s[i] = z;
    f2s[i] = z;
    f3s[i] = z;
  }

  return f1s, f2s, f3s;
}

fn _fe64_1_x3() -> stack u64[4], reg u64[4], stack u64[4]
{
  inline int i;
  stack u64[4] f1s f3s;
  reg   u64[4] f2;
  reg   u64 z;

  z = #set0();

  f1s[0] = 1;
  f2[0]  = 1;
  f3s[0] = 1;

  for i=1 to 4
  { f1s[i] = z;
    f2[i]  = z;
    f3s[i] = z;
  }

  return f1s, f2, f3s;
}

fn _bit_select(stack u8[32] e, reg u64 pos) -> reg u64
{
  reg u64 b p;

  p = pos;
  p >>= 3;
  b = (64u) e[(int) p];

  p = pos;
  p &= 7;
  b >>= p;

  b &= 1;

  return b;
}

fn _x25519_scalarmult(
  reg u64 out,
  reg u64 scalar,
  reg u64 point
)
{
  inline int i;
  stack u64[4] x1 x2 z2 x3 z3 t0 t1 t2;
  reg u64[4] x2r z2r z3r t1r;
  stack u8[32] e;
  reg u64 t swap pos b;
  stack u64 outs swaps poss;

  outs = out; // out dead

  for i=0 to 4
  { t = [scalar + 8*i];
    e[u64 i] = t; } // scalar dead

  e[0]  &= 0xf8;
  e[31] &= 0x7f;
  e[31] |= 0x40;

  x3, x1 = _fe64_frombytes(point); // point dead
  z2r, z3, x2 = _fe64_0_1_x2();

  pos = 254;
  swaps = 0;
  while
  {
    poss = pos;
    swap = swaps;

    b = _bit_select(e, pos);

    swap ^= b;

    x2,  x3 = _fe64_cswap_ssss(x2,  x3, swap);
    z2r, z3 = _fe64_cswap_rsrs(z2r, z3, swap);

    swaps = b;
                                               z2 = z2r;
    t0  = _fe64_sub_ssr(x2, z2r);
    x2  = _fe64_add_ssr(x2, z2r);

    t1  = _fe64_sub_sss(x3, z3);
    z2  = _fe64_add_sss(x3, z3);

    z3  = _fe64_mul_sss(x2, t1);
    z2  = _fe64_mul_sss(z2, t0);

    t2  = _fe64_sqr_ss(x2);
    t1r = _fe64_sqr_ss(t0);
                                               t1 = t1r;
    x3  = _fe64_add_sss(z3, z2);
    z2  = _fe64_sub_sss(z3, z2);

    x2  = _fe64_mul_ssr(t2, t1r);
    t0  = _fe64_sub_ssr(t2, t1r);

    z2  = _fe64_sqr_ss(z2);
    z3  = _fe64_mul121666_ss(t0);
    x3  = _fe64_sqr_ss(x3);

    t1  = _fe64_add_sss(t1, z3);
    z3  = _fe64_mul_sss(x1, z2);
    z2r = _fe64_mul_rss(t0, t1);

    pos = poss;
    pos -= 1;
  } (pos >=s 0)

  z2r = _fe64_invert(z2r);
  x2r = _fe64_mul_rsr(x2, z2r);
  x2r = _fe64_tobytes(x2r);

  out = outs;
  for i=0 to 4
  { [out + 8*i] = x2r[i]; }
}


// "How to (pre-)compute a ladder"
// implementation in C of the paper: https://github.com/armfazh/rfc7748_precomputed
fn _x25519_scalarmult_base(
  reg u64 out,
  reg u64 scalar,
  reg u64 table
)
{
  inline int i;
  stack u64[4] u1 z1 u2 z2 t1 t2 t3 t4;
  reg   u64[4] z1r u2r t1r t2r t3r;
  stack u8[32] e;
  reg u64 t swap pos b;
  stack u64 outs tables swaps poss;

  outs = out; // out dead
  tables = table; // table dead

  for i=0 to 4
  { t = [scalar + 8*i];
    e[u64 i] = t; } // scalar dead

  e[0]  &= 0xf8;
  e[31] &= 0x7f;
  e[31] |= 0x40;

  u1, z1r, z2 = _fe64_1_x3();

	u2r[0] = 0x7e94e1fec82faabd;
	u2r[1] = 0xbbf095ae14b2edf8;
	u2r[2] = 0xadc7a0b9235d48e2;
	u2r[3] = 0x1eaecdeee27cab34;

  u2 = u2r;

  pos = 3;
  swaps = 1;
  while
  {
    poss = pos;
    swap = swaps;

    b = _bit_select(e, pos);

    swap ^= b;

    u1,  u2 = _fe64_cswap_ssss(u1,  u2, swap);
    z1r, z2 = _fe64_cswap_rsrs(z1r, z2, swap);

    swaps = b;

    t2    = _fe64_sub_ssr(u1, z1r);
    t1    = _fe64_add_ssr(u1, z1r);

    table = tables;
    t3r   = _fe64_mul_rms(table, t2);

    t2    = _fe64_sub_ssr(t1, t3r);
    t1r   = _fe64_add_rsr(t1, t3r);

    t1    = _fe64_sqr_sr(t1r);
    t2    = _fe64_sqr_ss(t2);

    u1    = _fe64_mul_sss(z2, t1);
    z1r   = _fe64_mul_sss(u2, t2);

    tables += 8*4;

    pos = poss;
    pos += 1;
  } (pos < 255)

  pos = 0;
  while
  {
    poss = pos;

    t1 = _fe64_add_ssr(u1, z1r);
    t2 = _fe64_sub_ssr(u1, z1r);

    t1  = _fe64_sqr_ss(t1);
    t2r = _fe64_sqr_rs(t2);

    t3  = t2r;

    t2 = _fe64_sub_ssr(t1, t2r);

    t4 = _fe64_mul121666_ss(t2);

    t4 = _fe64_add_sss(t4, t3);

    u1  = _fe64_mul_sss(t1, t3);
    z1r = _fe64_mul_rss(t2, t4);

    pos = poss;
    pos += 1;
  } (pos < 3)

  t1r = _fe64_invert(z1r);
  t1r = _fe64_mul_rsr(u1, t1r);
  t1r = _fe64_tobytes(t1r);

  out = outs;
  for i=0 to 4
  { [out + 8*i] = t1r[i]; }
}
