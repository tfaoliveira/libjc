#ifndef CRYPTO_SCALARMULT_X25519_REF4_SCALARMULT2
#define CRYPTO_SCALARMULT_X25519_REF4_SCALARMULT2

#include "crypto_scalarmult/curve25519/common/x25519.jazz"
#include "crypto_scalarmult/curve25519/common/64/x25519_load4.jazz"
#include "crypto_scalarmult/curve25519/common/64/x25519_add4.jazz"
#include "crypto_scalarmult/curve25519/common/64/x25519_cswap4.jazz"
#include "crypto_scalarmult/curve25519/common/64/x25519_sub4.jazz"
#include "crypto_scalarmult/curve25519/common/64/x25519_tobytes4.jazz"

#include "crypto_scalarmult/curve25519/ref4/x25519_mul_a24.jazz"
#include "crypto_scalarmult/curve25519/ref4/x25519_mul.jazz"
#include "crypto_scalarmult/curve25519/ref4/x25519_sqr.jazz"
#include "crypto_scalarmult/curve25519/ref4/x25519_invert.jazz"

inline fn __add_and_double_ref4(
  stack u64[4] init,
  stack u64[4] x2,
  reg   u64[4] z2r,
  stack u64[4] x3,
  stack u64[4] z3) -> stack u64[4],
                      reg   u64[4],
                      stack u64[4],
                      stack u64[4]
{
  stack u64[4] z2 t0 t1 t2;
  reg u64[4] t1r;

  t0  = __sub4_ssr(x2, z2r);
  x2  = __add4_ssr(x2, z2r);

  t1  = __sub4_sss(x3, z3);
  z2  = __add4_sss(x3, z3);

  z3  = __ref4_mul_sss(x2, t1);
  z2  = __ref4_mul_sss(z2, t0);

  t2  = __ref4_sqr_ss(x2);
  t1  = __ref4_sqr_ss(t0);

  x3  = __add4_sss(z3, z2);
  z2  = __sub4_sss(z3, z2);

  x2  = __ref4_mul_sss(t2, t1);
  t0  = __sub4_sss(t2, t1);

  z2  = __ref4_sqr_ss(z2);
  z3  = __ref4_mul_a24_ss(t0, 121665);
  x3  = __ref4_sqr_ss(x3);

  t2  = __add4_sss(t2, z3);
  z3  = __ref4_mul_sss(init, z2);
  z2r = __ref4_mul_rss(t0, t2);

  return x2, z2r, x3, z3;
}

inline fn __montgomery_ladder_step_ref4(
  stack u64 k,
  stack u64[4] init,
  stack u64[4] x2,
  reg   u64[4] z2r,
  stack u64[4] x3,
  stack u64[4] z3,
  stack u64    swapped) -> stack u64,
                           stack u64[4],
                           reg   u64[4],
                           stack u64[4],
                           stack u64[4],
                           stack u64
{
  reg u64 toswap bit;

  bit, k = __next_bit(k);

  toswap  = swapped;
  toswap ^= bit;
  x2, z2r, x3, z3 = __cswap4(x2, z2r, x3, z3, toswap);
  swapped = bit;

  x2, z2r, x3, z3 = __add_and_double_ref4(init, x2, z2r, x3, z3);

  return k, x2, z2r, x3, z3, swapped;
}


inline fn __montgomery_ladder_ref4(reg u64[4] initr, stack u64[4] k)
  -> stack u64[4],
     reg u64[4],
     stack u64[4],
     stack u64[4]
{ 
  stack u64[4] init x2 x3 z3;
  reg u64[4] z2r;
  stack u64 ki is js swapped;
  reg u64 t i j;

  (x2,z2r,x3,z3) = __init_points(initr); 
  init = initr;

  swapped = 0;
  i = 4;
  j = 63;
  while
  {
    i -= 1;
    t  = k[(int) i];
    is = i;
    ki = t;

    while
    {
      j -= 1;
      js = j;
      (ki, x2, z2r, x3, z3, swapped) = __montgomery_ladder_step_ref4(ki, init, x2, z2r, x3, z3, swapped);
      j = js;
    }(j > 0)

    j = 64;
    i = is;
  }(i > 0)

  return x2, z2r, x3, z3;
}

inline fn __encode_point_ref4(stack u64[4] x2, reg u64[4] z2r) -> reg u64[4]
{
  stack u64[4] z2;
  reg u64[4] r;

  z2 = z2r;
  z2 = __ref4_invert(z2);
  r = __ref4_mul_rss(x2, z2);
  r = __tobytes4(r);

  return r;
}

inline fn __x25519_scalarmult_ref4(
  reg u64 rp,
  reg u64 kp,
  reg u64 up
)
{
  inline int i;
  stack u64[4] k;
  stack u64[4] x2 x3 z3;
  reg u64[4] u z2r r;
  reg u64 swap pos b;
  stack u64 rps swaps poss;

  rps = rp; // rp dead

  k = __decode_scalar_25519_shl1(kp); // kp dead
  u = __decode_u_coordinate(up); // up dead
  (x2,z2r,x3,z3) = __montgomery_ladder_ref4(u, k);
  r = __encode_point_ref4(x2,z2r);

  rp = rps;
  for i=0 to 4
  { [rp + 8*i] = r[i]; }
}

#ifdef EXPORT

export fn curve25519_ref4(reg u64 out scalar point)
{
  __x25519_scalarmult_ref4(out, scalar, point);
}

#endif

#endif

