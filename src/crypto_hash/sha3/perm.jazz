/*
   u256[6] rhotates_left = {
      0x0000000000000029000000000000002400000000000000120000000000000003
    , 0x000000000000001b000000000000001c000000000000003e0000000000000001
    , 0x000000000000002700000000000000380000000000000006000000000000002d
    , 0x00000000000000080000000000000037000000000000003d000000000000000a
    , 0x00000000000000140000000000000019000000000000000f0000000000000002
    , 0x000000000000000e0000000000000015000000000000002b000000000000002c 
    };
*/
    /*
	.quad	3,	18,	36,	41	# [2][0] [4][0] [1][0] [3][0] 
	.quad	1,	62,	28,	27	# [0][1] [0][2] [0][3] [0][4] 
	.quad	45,	6,	56,	39	# [3][1] [1][2] [4][3] [2][4]
	.quad	10,	61,	55,	8	# [2][1] [4][2] [1][3] [3][4]
	.quad	2,	15,	25,	20	# [4][1] [3][2] [2][3] [1][4]
	.quad	44,	43,	21,	14	# [1][1] [2][2] [3][3] [4][4] 
	*/
/*
    u256[6] rhotates_right = {
      0x0000000000000017000000000000001c000000000000002e000000000000003d
    , 0x000000000000002500000000000000240000000000000002000000000000003f
    , 0x00000000000000190000000000000008000000000000003a0000000000000013
    , 0x0000000000000038000000000000000900000000000000030000000000000036
    , 0x000000000000002c00000000000000270000000000000031000000000000003e
    , 0x0000000000000032000000000000002b00000000000000150000000000000014
	}
*/
	/*
	.quad	64-3,	64-18,	64-36,	64-41
	.quad	64-1,	64-62,	64-28,	64-27
	.quad	64-45,	64-6,	64-56,	64-39
	.quad	64-10,	64-61,	64-55,	64-8
	.quad	64-2,	64-15,	64-25,	64-20
	.quad	64-44,	64-43,	64-21,	64-14
	*/
/*
    u256[24] iotas = {
	  0x0000000000000001000000000000000100000000000000010000000000000001
	, 0x0000000000008082000000000000808200000000000080820000000000008082
	, 0x800000000000808a800000000000808a800000000000808a800000000000808a
	, 0x8000000080008000800000008000800080000000800080008000000080008000
	, 0x000000000000808b000000000000808b000000000000808b000000000000808b
	, 0x0000000080000001000000008000000100000000800000010000000080000001
	, 0x8000000080008081800000008000808180000000800080818000000080008081
	, 0x8000000000008009800000000000800980000000000080098000000000008009
	, 0x000000000000008a000000000000008a000000000000008a000000000000008a
	, 0x0000000000000088000000000000008800000000000000880000000000000088
	, 0x0000000080008009000000008000800900000000800080090000000080008009
	, 0x000000008000000a000000008000000a000000008000000a000000008000000a
	, 0x000000008000808b000000008000808b000000008000808b000000008000808b
	, 0x800000000000008b800000000000008b800000000000008b800000000000008b
	, 0x8000000000008089800000000000808980000000000080898000000000008089
	, 0x8000000000008003800000000000800380000000000080038000000000008003
	, 0x8000000000008002800000000000800280000000000080028000000000008002
	, 0x8000000000000080800000000000008080000000000000808000000000000080
	, 0x000000000000800a000000000000800a000000000000800a000000000000800a
	, 0x800000008000000a800000008000000a800000008000000a800000008000000a
	, 0x8000000080008081800000008000808180000000800080818000000080008081
	, 0x8000000000008080800000000000808080000000000080808000000000008080
	, 0x0000000080000001000000008000000100000000800000010000000080000001
	, 0x8000000080008008800000008000800880000000800080088000000080008008
    } 
*/

inline fn __KeccakF1600(reg u256 A00 A01 A20 A31 A21 A41 A11,
	  reg u64 _rhotates_left _rhotates_right _iotas) -> 
      reg u256, reg u256, reg u256, reg u256, reg u256, reg u256, reg u256 {

   reg u32 i; // why 32-bit? 
   reg u256 C00, C14; 
   reg u256 D00, D14;
   reg u256[9] T;
   reg bool zf;
   reg u64 rhotates_left rhotates_right iotas; // these should all be 32-bit

   rhotates_left = _rhotates_left + 96;
   rhotates_right = _rhotates_right + 96;
   iotas = _iotas;

   i = 2;
   while {
	/* ######################################### Theta */
	C00  = #x86_VPSHUFD_256(A20, 0x4e /*0b01001110 */);
	C14  = A41 ^4u64 A31 ;
	T[2] = A21 ^4u64 A11 ;
	C14  = C14 ^4u64 A01 ;
	C14  = C14 ^4u64 T[2];

	T[4] = #x86_VPERMQ(C14, 0x93 /* 0b10010011 */);
	C00 = C00 ^4u64 A20;
	T[0] = #x86_VPERMQ(C00, 0x4e /* 0b01001110 */);


    T[1] = C14 >>4u64 63; 
    T[2] = C14 +4u64 C14;
	T[1] = T[1] |4u64 T[2];

	D14 = #x86_VPERMQ(T[1], 0x39 /*0b00111001 */);
	D00 = T[1] ^4u64 T[4];
	D00 = #x86_VPERMQ(D00, 0x00 /*0b00000000 */);

	C00 = C00 ^4u64 A00;
	C00 = C00 ^4u64 T[0];

    T[0] = C00 >>4u64 63; 
    T[1] = C00 +4u64 C00;
	T[1] = T[1] |4u64 T[0];

	A20 = A20 ^4u64 D00;
	A00 = A00 ^4u64 D00;

    D14  = #x86_VPBLENDD_256(D14,T[1], (4u2)[3,0,0,0] /* 0b11000000 */);
    T[4] = #x86_VPBLENDD_256(T[4],C00, (4u2)[0,0,0,3] /* 0b00000011 */);
	D14 = D14 ^4u64 T[4];

	/* ######################################### Rho + Pi + pre-Chi shuffle */

	T[3] = #x86_VPSLLV_4u64(A20,(u256)[rhotates_left + 0*32-96]); //vpsllvq 0*32-96(%r8),$A20,@T[3]
	A20  = #x86_VPSRLV_4u64(A20,(u256)[rhotates_right+ 0*32-96]); //vpsrlvq	0*32-96(%r9),$A20,$A20
	A20 = A20 |4u64 T[3];

	A31 = A31 ^4u64 D14;
	T[4] = #x86_VPSLLV_4u64(A31,(u256)[rhotates_left + 2*32-96]); //vpsllvq 2*32-96(%r8),$A31,@T[4]
	A31  = #x86_VPSRLV_4u64(A31,(u256)[rhotates_right+ 2*32-96]); //vpsllvq 2*32-96(%r9),$A31,$A31
	A31 = A31 |4u64 T[4];

	A21 = A21 ^4u64 D14;
	T[5] = #x86_VPSLLV_4u64(A21,(u256)[rhotates_left + 3*32-96]); //vpsllvq 3*32-96(%r8),$A21,@T[5]
	A21  = #x86_VPSRLV_4u64(A21,(u256)[rhotates_right+ 3*32-96]); //vpsrlvq 3*32-96(%r9),$A21,$A21
	A21 = A21 |4u64 T[5];
			

	A41 = A41 ^4u64 D14;
	T[6] = #x86_VPSLLV_4u64(A41,(u256)[rhotates_left + 4*32-96]); //vpsllvq 4*32-96(%r8),$A41,@T[6]
	A41  = #x86_VPSRLV_4u64(A41,(u256)[rhotates_right+ 4*32-96]); //vpsrlvq 4*32-96(%r9),$A41,$A41
	A41 = A41 |4u64 T[6];

	A11 = A11 ^4u64 D14;
	T[3] = #x86_VPERMQ(A20, 0x8d /*0b10001101 */);
	T[4] = #x86_VPERMQ(A31, 0x8d /*0b10001101 */);
	T[7] = #x86_VPSLLV_4u64(A11,(u256)[rhotates_left + 5*32-96]); //vpsllvq 5*32-96(%r8),$A11,@T[7]
	T[1] = #x86_VPSRLV_4u64(A11,(u256)[rhotates_right+ 5*32-96]); //vpsrlvq 5*32-96(%r9),$A11,@T[1]
	T[1] = T[1] |4u64 T[7];

	A01 = A01 ^4u64 D14;
	T[5] = #x86_VPERMQ(A21, 0x1b /*0b00011011 */);
	T[6] = #x86_VPERMQ(A41, 0x72 /*0b01110010 */);
	T[8] = #x86_VPSLLV_4u64(A01,(u256)[rhotates_left + 1*32-96]); //vpsllvq 1*32-96(%r8),$A01,@T[8]
	T[2] = #x86_VPSRLV_4u64(A01,(u256)[rhotates_right+ 1*32-96]); //vpsrlvq 1*32-96(%r9),$A01,@T[2]
	T[2] = T[2] |4u64 T[8];


	/* ######################################### Chi */
    T[7] = T[1] >>2u128 8; // vpsrldq
	T[0] = #x86_VPANDN_256(T[1],T[7]);

    A31  = #x86_VPBLENDD_256(T[2],T[6], (4u2)[0,0,3,0] );
    T[8] = #x86_VPBLENDD_256(T[4],T[2], (4u2)[0,0,3,0] );
    A41  = #x86_VPBLENDD_256(T[3],T[4], (4u2)[0,0,3,0] );
    T[7] = #x86_VPBLENDD_256(T[2],T[3], (4u2)[0,0,3,0] );

    A31  = #x86_VPBLENDD_256(A31, T[4], (4u2)[0,3,0,0] );
    T[8] = #x86_VPBLENDD_256(T[8],T[5], (4u2)[0,3,0,0] );
    A41  = #x86_VPBLENDD_256(A41, T[2], (4u2)[0,3,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[6], (4u2)[0,3,0,0] );

    A31  = #x86_VPBLENDD_256(A31, T[5], (4u2)[3,0,0,0] );
    T[8] = #x86_VPBLENDD_256(T[8],T[6], (4u2)[3,0,0,0] );
    A41  = #x86_VPBLENDD_256(A41, T[6], (4u2)[3,0,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[4], (4u2)[3,0,0,0] );

	A31 = #x86_VPANDN_256(A31,T[8]);
	A41 = #x86_VPANDN_256(A41,T[7]);

    A11  = #x86_VPBLENDD_256(T[5],T[2], (4u2)[0,0,3,0] );
    T[8] = #x86_VPBLENDD_256(T[3],T[5], (4u2)[0,0,3,0] ); 
	A31 = A31 ^4u64 T[3];

    A11  = #x86_VPBLENDD_256(A11,T[3],  (4u2)[0,3,0,0] );
    T[8] = #x86_VPBLENDD_256(T[8],T[4], (4u2)[0,3,0,0] );
	A41 = A41 ^4u64 T[5];

    A11  = #x86_VPBLENDD_256(A11,T[4],  (4u2)[3,0,0,0] );
    T[8] = #x86_VPBLENDD_256(T[8],T[2], (4u2)[3,0,0,0] );
	A11 = #x86_VPANDN_256(A11,T[8]);
	A11 = A11 ^4u64 T[6];

	A21 = #x86_VPERMQ(T[1], 0x1e /*0b00011110 */);
    T[8] = #x86_VPBLENDD_256(A21,A00, (4u2)[0,3,0,0] );
	A01 = #x86_VPERMQ(T[1], 0x39 /*0b00111001 */);
    A01 = #x86_VPBLENDD_256(A01,A00, (4u2)[3,0,0,0] );
	A01 = #x86_VPANDN_256(A01,T[8]);

    A20  = #x86_VPBLENDD_256(T[4],T[5], (4u2)[0,0,3,0] );
    T[7] = #x86_VPBLENDD_256(T[6],T[4], (4u2)[0,0,3,0] );
    A20  = #x86_VPBLENDD_256(A20, T[6], (4u2)[0,3,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[3], (4u2)[0,3,0,0] );
    A20  = #x86_VPBLENDD_256(A20, T[3], (4u2)[3,0,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[5], (4u2)[3,0,0,0] );

	A20 = #x86_VPANDN_256(A20,T[7]);
	A20 = A20 ^4u64 T[2];

	T[0] = #x86_VPERMQ(T[0], 0x00/*0b00000000 */);
	A31  = #x86_VPERMQ(A31, 0x1b/*0b00011011 */);
	A41  = #x86_VPERMQ(A41, 0x8d/*0b10001101 */);
	A11  = #x86_VPERMQ(A11, 0x72/*0b01110010 */);

    A21  = #x86_VPBLENDD_256(T[6],T[3], (4u2)[0,0,3,0] );
    T[7] = #x86_VPBLENDD_256(T[5],T[6], (4u2)[0,0,3,0] );
    A21  = #x86_VPBLENDD_256(A21, T[5], (4u2)[0,3,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[2], (4u2)[0,3,0,0] );
    A21  = #x86_VPBLENDD_256(A21, T[2], (4u2)[3,0,0,0] );
    T[7] = #x86_VPBLENDD_256(T[7],T[3], (4u2)[3,0,0,0] );

	A21 = #x86_VPANDN_256(A21,T[7]);

	A00 = A00 ^4u64 T[0];
	A01 = A01 ^4u64 T[1];
	A21 = A21 ^4u64 T[4];

    /*	######################################### Iota */
	A00 = A00 ^4u64 (u256)[iotas + 0];
	iotas = iotas + 32;

    (_,_,_,zf,i) = #x86_DEC_32(i); // dec = decl?
   } (!zf) 
   return A00, A01, A20, A31, A21, A41, A11;
}

export fn __KeccakF1600_wrapper(reg u64 r _rhotates_left _rhotates_right _iotas) {
	reg u256 A00, A01, A20, A31, A21, A41, A11;

    A00 = (u256)[r +   0];
    A01 = (u256)[r +  32];
    A20 = (u256)[r +  64];
    A31 = (u256)[r +  96];
    A21 = (u256)[r + 128];
    A41 = (u256)[r + 160];
    A11 = (u256)[r + 192];

	A00, A01, A20, A31, A21, A41, A11 = __KeccakF1600(A00, A01, A20, A31, A21, A41, A11,
		                                    _rhotates_left, _rhotates_right, _iotas);

    (u256)[r +   0] = A00;
    (u256)[r +  32] = A01;
    (u256)[r +  64] = A20;
    (u256)[r +  96] = A31;
    (u256)[r + 128] = A21;
    (u256)[r + 160] = A41;
    (u256)[r + 192] = A11;
}













